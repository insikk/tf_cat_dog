{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data. \n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = 'data/records'\n",
    "TRAIN_DATA_PATH = 'data/thumb280_train'\n",
    "TEST_DATA_PATH = 'data/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_CLASSES = read_data.IMG_CLASSES\n",
    "NUM_CLASSES = len(read_data.IMG_CLASSES)\n",
    "IMG_HEIGHT = read_data.IMG_HEIGHT\n",
    "IMG_WIDTH = read_data.IMG_WIDTH\n",
    "IMG_CHANNELS = read_data.IMG_CHANNELS\n",
    "IMG_PIXELS = IMG_HEIGHT * IMG_WIDTH * IMG_CHANNELS\n",
    "NUM_TRAIN_EXAMPLES = read_data.NUM_TRAIN_EXAMPLES\n",
    "NUM_VALIDATION_EXAMPLES = read_data.NUM_VALIDATION_EXAMPLES\n",
    "NUM_TEST_EXAMPLES = read_data.NUM_TEST_EXAMPLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "from os import  walk\n",
    "\n",
    "def read_images(path, classes, img_height = 128, img_width = 128, img_channels = 3, log=False):\n",
    "    filenames = next(walk(path))[2]\n",
    "    num_files = len(filenames)\n",
    "    \n",
    "    if log:\n",
    "        print(\"Reading images from %s ... %d files are there\" % (path, num_files))\n",
    "\n",
    "    images = np.zeros((num_files, img_height, img_width, img_channels), dtype=np.uint8)\n",
    "    labels = np.zeros((num_files, ), dtype=np.uint8)\n",
    "    min_w = 10000\n",
    "    min_h = 10000\n",
    "    max_h = 0\n",
    "    max_w = 0\n",
    "    count = float(len(filenames))\n",
    "    sum_shape = [0.0, 0.0]\n",
    "    for i, filename in enumerate(filenames):\n",
    "        if i % 2000 == 0 and i != 0:\n",
    "            if log:\n",
    "                print(\"%d / %d\" % (i, len(filenames))) \n",
    "        \n",
    "        img = imread(join(path, filename))\n",
    "        w, h, _ = img.shape\n",
    "        \n",
    "        if w < min_w:\n",
    "            min_w = w\n",
    "            min_w_shape = img.shape\n",
    "        if w > max_w:\n",
    "            max_w = w\n",
    "            max_w_shape = img.shape\n",
    "        if h < min_h:\n",
    "            min_h = h\n",
    "            min_h_shape = img.shape\n",
    "        if h > max_h:\n",
    "            max_h = h\n",
    "            max_h_shape = img.shape\n",
    "        sum_shape[0] = sum_shape[0] + h\n",
    "        sum_shape[1] = sum_shape[1] + w\n",
    "        # img = imresize(img, (img_height, img_width))\n",
    "        # images[i, :, :, :] = img\n",
    "        class_name = filename[0:3].lower() # Luckily both 'cat' and 'dog' have 3 characters\n",
    "        if class_name == 'cat' or class_name == 'dog':\n",
    "            labels[i] = classes.index(class_name)\n",
    "    \n",
    "    print(\"min_w: {}, {}\".format(min_w, min_w_shape))\n",
    "\n",
    "    print(\"max_w: {}, {}\".format(max_w, max_w_shape))\n",
    "\n",
    "    print(\"min_h: {}, {}\".format(min_h, min_h_shape))\n",
    "\n",
    "    print(\"max_h: {}, {}\".format(max_h, max_h_shape))\n",
    "\n",
    "    print(\"mean shape(h, w) : {} {}\".format(sum_shape[0]/count, sum_shape[1]/count))\n",
    "    print(\"Done!\") \n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from data/thumb280_train ... 25000 files are there\n",
      "2000 / 25000\n",
      "4000 / 25000\n",
      "6000 / 25000\n",
      "8000 / 25000\n",
      "10000 / 25000\n",
      "12000 / 25000\n",
      "14000 / 25000\n",
      "16000 / 25000\n",
      "18000 / 25000\n",
      "20000 / 25000\n",
      "22000 / 25000\n",
      "24000 / 25000\n",
      "min_w: 32, (32, 60, 3)\n",
      "max_w: 280, (280, 210, 3)\n",
      "min_h: 42, (62, 42, 3)\n",
      "max_h: 280, (210, 280, 3)\n",
      "mean shape(h, w) : 255.27684 228.71004\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "log_flag = True\n",
    "\n",
    "train_images, train_labels = read_images(TRAIN_DATA_PATH, IMG_CLASSES,\n",
    "                                                       IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cats: 12500\n",
      "number of dogs: 12500\n",
      "[ 1262  3796   962 10183 10783]\n",
      "[24452 22067 23385 18260 20726]\n",
      "val_cats:: 2500\n",
      "train_cats:: 10000\n"
     ]
    }
   ],
   "source": [
    "cat_idx = np.where(train_labels == 1)[0]\n",
    "print(\"number of cats:\", len(cat_idx))\n",
    "dog_idx = np.where(train_labels == 0)[0]\n",
    "print(\"number of dogs:\", len(dog_idx))\n",
    "\n",
    "cat_val_idx = np.random.choice(cat_idx, 2500, replace=False)\n",
    "print(cat_val_idx[:5])\n",
    "\n",
    "dog_val_idx = np.random.choice(dog_idx, 2500, replace=False)\n",
    "print(dog_val_idx[:5])\n",
    "cat_train_idx = np.setdiff1d(cat_idx, cat_val_idx)\n",
    "\n",
    "print(\"val_cats::\", len(cat_val_idx))\n",
    "print(\"train_cats::\", len(cat_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_idx len: 5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21731, 13506,  1180,  8276, 11055])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx = np.random.permutation(np.array(cat_val_idx.tolist() + dog_val_idx.tolist()))\n",
    "print(\"val_idx len:\", val_idx.size)\n",
    "val_idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[2 1 4]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(range(5))\n",
    "print(arr)\n",
    "b = arr[[2, 1, 4]]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_to(images, labels, name, log=False):\n",
    "    if log:\n",
    "        print(\"converting %s to tfrecords...\"%(name))\n",
    "    num_examples = labels.shape[0]\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError(\"Images size %d does not match label size %d.\" %\n",
    "                     (images.shape[0], num_examples))\n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "    depth = images.shape[3]\n",
    "\n",
    "    filename = join(DATA_DIR, name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        if index % 2000 == 0:\n",
    "            if log:\n",
    "                print(\"%d / %d\" % (index, num_examples)) \n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'label': _int64_feature(int(labels[index])),   # NOT assuming one-hot format of original data\n",
    "            'image_raw': _bytes_feature(image_raw)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    if log:\n",
    "        print(\"Done!\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from data/train/ ... 25000 files are there\n",
      "0 / 25000\n",
      "2000 / 25000\n",
      "4000 / 25000\n",
      "6000 / 25000\n",
      "8000 / 25000\n",
      "10000 / 25000\n",
      "12000 / 25000\n",
      "14000 / 25000\n",
      "16000 / 25000\n",
      "18000 / 25000\n",
      "20000 / 25000\n",
      "22000 / 25000\n",
      "24000 / 25000\n",
      "Done!\n",
      "converting train to tfrecords...\n",
      "Writing data/train.tfrecords\n",
      "0 / 22500\n",
      "2000 / 22500\n",
      "4000 / 22500\n",
      "6000 / 22500\n",
      "8000 / 22500\n",
      "10000 / 22500\n",
      "12000 / 22500\n",
      "14000 / 22500\n",
      "16000 / 22500\n",
      "18000 / 22500\n",
      "20000 / 22500\n",
      "22000 / 22500\n",
      "Done!\n",
      "converting validation to tfrecords...\n",
      "Writing data/validation.tfrecords\n",
      "0 / 2500\n",
      "2000 / 2500\n",
      "Done!\n",
      "Reading test images...\n",
      "Reading images from data/test/ ... 12500 files are there\n",
      "0 / 12500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'237' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fb263df79539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading test images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m test_images, test_labels = read_images(TEST_DATA_PATH, IMG_CLASSES,\n\u001b[0;32m---> 20\u001b[0;31m                                                      IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-958dd6f10ad5>\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(path, classes, img_height, img_width, img_channels, log)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Luckily both 'cat' and 'dog' have 3 characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '237' is not in list"
     ]
    }
   ],
   "source": [
    "log_flag = True\n",
    "\n",
    "train_images, train_labels = read_images(TRAIN_DATA_PATH, IMG_CLASSES,\n",
    "                                                       IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n",
    "\n",
    "# Generate a validation set.\n",
    "validation_size = int(VALIDATION_SET_FRACTION * train_images.shape[0])\n",
    "validation_images = train_images[:validation_size, :, :, :]\n",
    "validation_labels = train_labels[:validation_size]\n",
    "train_images = train_images[validation_size:, :, :, :]\n",
    "train_labels = train_labels[validation_size:]\n",
    "\n",
    "# Convert to Examples and write the result to TFRecords.\n",
    "\n",
    "convert_to(train_images, train_labels, 'train', log_flag)\n",
    "convert_to(validation_images, validation_labels, 'validation', log_flag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test images...\n",
      "Reading images from data/test/ ... 12500 files are there\n",
      "0 / 12500\n",
      "2000 / 12500\n",
      "4000 / 12500\n",
      "6000 / 12500\n",
      "8000 / 12500\n",
      "10000 / 12500\n",
      "12000 / 12500\n",
      "Done!\n",
      "converting test to tfrecords...\n",
      "Writing data/test.tfrecords\n",
      "0 / 12500\n",
      "2000 / 12500\n",
      "4000 / 12500\n",
      "6000 / 12500\n",
      "8000 / 12500\n",
      "10000 / 12500\n",
      "12000 / 12500\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading test images...\")\n",
    "test_images, test_labels = read_images(TEST_DATA_PATH, IMG_CLASSES,\n",
    "                                                     IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n",
    "\n",
    "convert_to(test_images, test_labels, 'test', log_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
