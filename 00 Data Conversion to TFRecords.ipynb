{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecords from Data\n",
    "\n",
    "* TF Records are easy way to utilize tensorflow input queue. \n",
    "* It reduce burden of file IO. \n",
    "\n",
    "Just convert it to TFExample form. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "import read_data\n",
    "# import manage_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = 'data/records'\n",
    "TRAIN_DATA_PATH = 'data/train/'\n",
    "TEST_DATA_PATH = 'data/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "NUM_CLASSES = len(read_data.IMG_CLASSES)\n",
    "IMG_HEIGHT = read_data.IMG_HEIGHT\n",
    "IMG_WIDTH = read_data.IMG_WIDTH\n",
    "IMG_CHANNELS = read_data.IMG_CHANNELS\n",
    "IMG_PIXELS = IMG_HEIGHT * IMG_WIDTH * IMG_CHANNELS\n",
    "NUM_TRAIN_EXAMPLES = read_data.NUM_TRAIN_EXAMPLES\n",
    "NUM_VALIDATION_EXAMPLES = read_data.NUM_VALIDATION_EXAMPLES\n",
    "NUM_TEST_EXAMPLES = read_data.NUM_TEST_EXAMPLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "from os import  walk\n",
    "\n",
    "def read_images(path, classes, img_height = 128, img_width = 128, img_channels = 3, log=False):\n",
    "    \n",
    "\n",
    "    filenames = next(walk(path))[2]\n",
    "    num_files = len(filenames)\n",
    "    \n",
    "    if log:\n",
    "        print(\"Reading images from %s ... %d files are there\" % (path, num_files))\n",
    "\n",
    "    images = np.zeros((num_files, img_height, img_width, img_channels), dtype=np.uint8)\n",
    "    labels = np.zeros((num_files, ), dtype=np.uint8)\n",
    "    for i, filename in enumerate(filenames):\n",
    "        if i % 2000 == 0:\n",
    "            if log:\n",
    "                print(\"%d / %d\" % (i, len(filenames))) \n",
    "        img = imread(join(path, filename))\n",
    "        img = imresize(img, (img_height, img_width))\n",
    "        images[i, :, :, :] = img\n",
    "        class_name = filename[0:3].lower() # Luckily both 'cat' and 'dog' have 3 characters\n",
    "        if class_name is 'cat' or class_name is 'dog':\n",
    "            labels[i] = classes.index(class_name)\n",
    "        \n",
    "    if log:\n",
    "        print(\"Done!\") \n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_to(images, labels, name, log=False):\n",
    "    if log:\n",
    "        print(\"converting %s to tfrecords...\"%(name))\n",
    "    num_examples = labels.shape[0]\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError(\"Images size %d does not match label size %d.\" %\n",
    "                     (images.shape[0], num_examples))\n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "    depth = images.shape[3]\n",
    "\n",
    "    filename = join(DATA_DIR, name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        if index % 2000 == 0:\n",
    "            if log:\n",
    "                print(\"%d / %d\" % (index, num_examples)) \n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'label': _int64_feature(int(labels[index])),   # NOT assuming one-hot format of original data\n",
    "            'image_raw': _bytes_feature(image_raw)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    if log:\n",
    "        print(\"Done!\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from data/train/ ... 25000 files are there\n",
      "0 / 25000\n",
      "2000 / 25000\n",
      "4000 / 25000\n",
      "6000 / 25000\n",
      "8000 / 25000\n",
      "10000 / 25000\n",
      "12000 / 25000\n",
      "14000 / 25000\n",
      "16000 / 25000\n",
      "18000 / 25000\n",
      "20000 / 25000\n",
      "22000 / 25000\n",
      "24000 / 25000\n",
      "Done!\n",
      "converting train to tfrecords...\n",
      "Writing data/train.tfrecords\n",
      "0 / 22500\n",
      "2000 / 22500\n",
      "4000 / 22500\n",
      "6000 / 22500\n",
      "8000 / 22500\n",
      "10000 / 22500\n",
      "12000 / 22500\n",
      "14000 / 22500\n",
      "16000 / 22500\n",
      "18000 / 22500\n",
      "20000 / 22500\n",
      "22000 / 22500\n",
      "Done!\n",
      "converting validation to tfrecords...\n",
      "Writing data/validation.tfrecords\n",
      "0 / 2500\n",
      "2000 / 2500\n",
      "Done!\n",
      "Reading test images...\n",
      "Reading images from data/test/ ... 12500 files are there\n",
      "0 / 12500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'237' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fb263df79539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading test images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m test_images, test_labels = read_images(TEST_DATA_PATH, IMG_CLASSES,\n\u001b[0;32m---> 20\u001b[0;31m                                                      IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-958dd6f10ad5>\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(path, classes, img_height, img_width, img_channels, log)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Luckily both 'cat' and 'dog' have 3 characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '237' is not in list"
     ]
    }
   ],
   "source": [
    "log_flag = True\n",
    "\n",
    "train_images, train_labels = read_images(TRAIN_DATA_PATH, IMG_CLASSES,\n",
    "                                                       IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n",
    "\n",
    "# Generate a validation set.\n",
    "validation_size = int(VALIDATION_SET_FRACTION * train_images.shape[0])\n",
    "validation_images = train_images[:validation_size, :, :, :]\n",
    "validation_labels = train_labels[:validation_size]\n",
    "train_images = train_images[validation_size:, :, :, :]\n",
    "train_labels = train_labels[validation_size:]\n",
    "\n",
    "# Convert to Examples and write the result to TFRecords.\n",
    "\n",
    "convert_to(train_images, train_labels, 'train', log_flag)\n",
    "convert_to(validation_images, validation_labels, 'validation', log_flag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test images...\n",
      "Reading images from data/test/ ... 12500 files are there\n",
      "0 / 12500\n",
      "2000 / 12500\n",
      "4000 / 12500\n",
      "6000 / 12500\n",
      "8000 / 12500\n",
      "10000 / 12500\n",
      "12000 / 12500\n",
      "Done!\n",
      "converting test to tfrecords...\n",
      "Writing data/test.tfrecords\n",
      "0 / 12500\n",
      "2000 / 12500\n",
      "4000 / 12500\n",
      "6000 / 12500\n",
      "8000 / 12500\n",
      "10000 / 12500\n",
      "12000 / 12500\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading test images...\")\n",
    "test_images, test_labels = read_images(TEST_DATA_PATH, IMG_CLASSES,\n",
    "                                                     IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, log_flag)\n",
    "\n",
    "convert_to(test_images, test_labels, 'test', log_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
